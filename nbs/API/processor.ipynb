{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processor\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from llm_data_extractor.models import ExtractionResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def format_for_db(results: List[ExtractionResult], \n",
    "                  source_id: Optional[str] = None,\n",
    "                  batch_id: Optional[str] = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Format extraction results for database insertion.\n",
    "    \n",
    "    Args:\n",
    "        results: List of ExtractionResult objects\n",
    "        source_id: Optional identifier for the source document/text\n",
    "        batch_id: Optional identifier for the processing batch\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries ready for database insertion\n",
    "    \"\"\"\n",
    "    \n",
    "    formatted_results = []\n",
    "    \n",
    "    for result in results:\n",
    "        record = {\n",
    "            'question_id': result.question_id,\n",
    "            'raw_answer': result.raw_answer,\n",
    "            'parsed_answer': _serialize_answer(result.parsed_answer),\n",
    "            'confidence': result.confidence,\n",
    "            'is_valid': result.is_valid,\n",
    "            'validation_error': result.validation_error,\n",
    "            'processed_at': result.timestamp.isoformat(),\n",
    "            'source_id': source_id,\n",
    "            'batch_id': batch_id\n",
    "        }\n",
    "        \n",
    "        formatted_results.append(record)\n",
    "    \n",
    "    return formatted_results\n",
    "\n",
    "\n",
    "def format_for_target_tables(results: List[ExtractionResult], \n",
    "                           questions_map: Dict[str, Any]) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Format results grouped by target table for direct insertion into business tables.\n",
    "    \n",
    "    Args:\n",
    "        results: List of ExtractionResult objects\n",
    "        questions_map: Map of question_id to Question objects\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with table names as keys and records as values\n",
    "    \"\"\"\n",
    "    \n",
    "    table_records = {}\n",
    "    \n",
    "    for result in results:\n",
    "        if not result.is_valid:\n",
    "            continue  # Skip invalid results\n",
    "            \n",
    "        question = questions_map.get(result.question_id)\n",
    "        if not question:\n",
    "            continue\n",
    "            \n",
    "        table_name = question.target_table\n",
    "        field_name = question.target_field\n",
    "        \n",
    "        if table_name not in table_records:\n",
    "            table_records[table_name] = {}\n",
    "        \n",
    "        # Use source_id or batch_id as the record key\n",
    "        # This assumes one record per source document per table\n",
    "        record_key = 'default'  # You might want to pass this in\n",
    "        \n",
    "        if record_key not in table_records[table_name]:\n",
    "            table_records[table_name][record_key] = {}\n",
    "        \n",
    "        table_records[table_name][record_key][field_name] = result.parsed_answer\n",
    "        table_records[table_name][record_key][f'{field_name}_confidence'] = result.confidence\n",
    "        table_records[table_name][record_key][f'{field_name}_processed_at'] = result.timestamp.isoformat()\n",
    "    \n",
    "    # Convert to list format for each table\n",
    "    formatted_tables = {}\n",
    "    for table_name, records in table_records.items():\n",
    "        formatted_tables[table_name] = list(records.values())\n",
    "    \n",
    "    return formatted_tables\n",
    "\n",
    "\n",
    "def create_summary_stats(results: List[ExtractionResult]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create summary statistics for a batch of extraction results.\n",
    "    \n",
    "    Args:\n",
    "        results: List of ExtractionResult objects\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with summary statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    if not results:\n",
    "        return {\n",
    "            'total_questions': 0,\n",
    "            'valid_answers': 0,\n",
    "            'invalid_answers': 0,\n",
    "            'success_rate': 0.0,\n",
    "            'avg_confidence': 0.0\n",
    "        }\n",
    "    \n",
    "    total_questions = len(results)\n",
    "    valid_answers = sum(1 for r in results if r.is_valid)\n",
    "    invalid_answers = total_questions - valid_answers\n",
    "    success_rate = valid_answers / total_questions\n",
    "    \n",
    "    # Calculate average confidence for valid answers\n",
    "    valid_confidences = [r.confidence for r in results if r.is_valid and r.confidence is not None]\n",
    "    avg_confidence = sum(valid_confidences) / len(valid_confidences) if valid_confidences else 0.0\n",
    "    \n",
    "    # Get validation error categories\n",
    "    error_types = {}\n",
    "    for result in results:\n",
    "        if not result.is_valid and result.validation_error:\n",
    "            error_type = result.validation_error.split(':')[0]  # Get first part of error\n",
    "            error_types[error_type] = error_types.get(error_type, 0) + 1\n",
    "    \n",
    "    return {\n",
    "        'total_questions': total_questions,\n",
    "        'valid_answers': valid_answers,\n",
    "        'invalid_answers': invalid_answers,\n",
    "        'success_rate': round(success_rate, 3),\n",
    "        'avg_confidence': round(avg_confidence, 3),\n",
    "        'error_types': error_types,\n",
    "        'processed_at': datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "\n",
    "def _serialize_answer(answer: Any) -> str:\n",
    "    \"\"\"\n",
    "    Serialize parsed answer for database storage.\n",
    "    \n",
    "    Args:\n",
    "        answer: The parsed answer value\n",
    "        \n",
    "    Returns:\n",
    "        String representation suitable for database storage\n",
    "    \"\"\"\n",
    "    \n",
    "    if answer is None:\n",
    "        return None\n",
    "    \n",
    "    # Handle datetime objects\n",
    "    if isinstance(answer, datetime):\n",
    "        return answer.isoformat()\n",
    "    \n",
    "    # Handle lists and complex objects\n",
    "    if isinstance(answer, (list, dict)):\n",
    "        return json.dumps(answer)\n",
    "    \n",
    "    # Handle primitive types\n",
    "    return str(answer)\n",
    "\n",
    "\n",
    "def create_audit_record(batch_id: str, \n",
    "                       source_id: str,\n",
    "                       total_questions: int,\n",
    "                       processing_time_seconds: float,\n",
    "                       llm_config: Dict[str, Any],\n",
    "                       summary_stats: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create an audit record for the extraction batch.\n",
    "    \n",
    "    Args:\n",
    "        batch_id: Unique identifier for the batch\n",
    "        source_id: Identifier for the source document\n",
    "        total_questions: Number of questions processed\n",
    "        processing_time_seconds: Time taken for processing\n",
    "        llm_config: Configuration used for LLM calls\n",
    "        summary_stats: Summary statistics from create_summary_stats\n",
    "        \n",
    "    Returns:\n",
    "        Audit record dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        'batch_id': batch_id,\n",
    "        'source_id': source_id,\n",
    "        'total_questions': total_questions,\n",
    "        'processing_time_seconds': round(processing_time_seconds, 2),\n",
    "        'llm_model': llm_config.get('model_name'),\n",
    "        'llm_temperature': llm_config.get('temperature'),\n",
    "        'success_rate': summary_stats.get('success_rate'),\n",
    "        'avg_confidence': summary_stats.get('avg_confidence'),\n",
    "        'processed_at': datetime.now().isoformat(),\n",
    "        'config_snapshot': json.dumps(llm_config)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
